2025-01-30 23:04:54,169 INFO    MainThread:26852 [wandb_setup.py:_flush():68] Current SDK version is 0.19.4
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_setup.py:_flush():68] Configure stats pid to 26852
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_setup.py:_flush():68] Loading settings from C:\Users\TMB\.config\wandb\settings
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_setup.py:_flush():68] Loading settings from C:\dev\EE569\Assignment2-LLM\wandb\settings
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_init.py:setup_run_log_directory():624] Logging user logs to C:\dev\EE569\Assignment2-LLM\wandb\run-20250130_230454-vkm9yk21\logs\debug.log
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_init.py:setup_run_log_directory():625] Logging internal logs to C:\dev\EE569\Assignment2-LLM\wandb\run-20250130_230454-vkm9yk21\logs\debug-internal.log
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_init.py:init():743] calling init triggers
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_init.py:init():748] wandb.init called with sweep_config: {}
config: {'project': 'llmapps', 'entity': None, 'job_type': 'production', 'vector_store_artifact': 'tmbuot-university-of-tripoli/llmapps/vector_store:latest', 'chat_prompt_artifact': 'tmbuot-university-of-tripoli/llmapps/chat_prompt:latest', 'chat_temperature': 0.3, 'max_fallback_retries': 1, 'model_name': 'gpt-4o-mini', 'eval_model': 'gpt-4o-mini', 'eval_artifact': 'tmbuot-university-of-tripoli/llmapps/generated_examples:v0'}
2025-01-30 23:04:54,177 INFO    MainThread:26852 [wandb_init.py:init():776] starting backend
2025-01-30 23:04:54,418 INFO    MainThread:26852 [wandb_init.py:init():780] sending inform_init request
2025-01-30 23:04:54,480 INFO    MainThread:26852 [backend.py:_multiprocessing_setup():97] multiprocessing start_methods=spawn, using: spawn
2025-01-30 23:04:54,481 INFO    MainThread:26852 [wandb_init.py:init():795] backend started and connected
2025-01-30 23:04:54,489 INFO    MainThread:26852 [wandb_init.py:init():888] updated telemetry
2025-01-30 23:04:54,492 INFO    MainThread:26852 [wandb_init.py:init():915] communicating run to backend with 90.0 second timeout
2025-01-30 23:04:55,091 INFO    MainThread:26852 [wandb_init.py:init():967] starting run threads in backend
2025-01-30 23:04:55,445 INFO    MainThread:26852 [wandb_run.py:_console_start():2409] atexit reg
2025-01-30 23:04:55,447 INFO    MainThread:26852 [wandb_run.py:_redirect():2259] redirect: wrap_raw
2025-01-30 23:04:55,447 INFO    MainThread:26852 [wandb_run.py:_redirect():2324] Wrapping output streams.
2025-01-30 23:04:55,447 INFO    MainThread:26852 [wandb_run.py:_redirect():2349] Redirects installed.
2025-01-30 23:04:55,452 INFO    MainThread:26852 [wandb_init.py:init():1009] run started, returning control to user process
2025-01-30 23:05:33,256 ERROR   MainThread:26852 [util.py:get_module():249] Error importing optional module torch
Traceback (most recent call last):
  File "c:\Python312\Lib\site-packages\wandb\util.py", line 215, in import_module_lazy
    return sys.modules[name]
           ~~~~~~~~~~~^^^^^^
KeyError: 'torch'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Python312\Lib\site-packages\wandb\util.py", line 244, in get_module
    return import_module_lazy(name)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Python312\Lib\site-packages\wandb\util.py", line 219, in import_module_lazy
    raise ModuleNotFoundError
ModuleNotFoundError
